{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using SageMaker PyTorch Container\n",
    "\n",
    "Kernel `conda_pytorch_p39` works well with this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Host](#Host)\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "MNIST is a widely used dataset for handwritten digit classification. It consists of 70,000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60,000 training images and 10,000 test images. There are 10 classes (one for each of the 10 digits). This tutorial will show how to train and test an MNIST model on SageMaker using PyTorch. It also shows how to use SageMaker Automatic Model Tuning to select appropriate hyperparameters in order to get the best model. \n",
    "\n",
    "For more information about the PyTorch in SageMaker, please visit [sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-containers) and [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk) github repositories.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "_This notebook was created and tested on an ml.m4.xlarge notebook instance._\n",
    "\n",
    "Let's start by creating a SageMaker session and specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the `sagemaker.get_execution_role()` with a the appropriate full IAM role arn string(s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/DEMO-pytorch-mnist'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "### Getting the data\n",
    "\n",
    "Download the built-in MNIST dataset from the torchvision library. We also apply the following transformations -\n",
    "- convert the input data into `torch.FloatTensor` and scale the pixel values to the range: `[0.0, 1.0]`.\n",
    "- normalize the dataset using the mean and standard deviation of the pixel values from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0074694156646728516,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 9912422,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc8a060ba174a959766fe5b36c57362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005825519561767578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 28881,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07dab74e2aa14ea3a81384140f984412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0053751468658447266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1648877,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e978e6790ed449768bde4b423f25366e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0058650970458984375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4542,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edbbbc75b0214827a656e306cd8c1488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "           )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "datasets.MNIST('data', download=True, transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the data to S3\n",
    "We are going to use the `sagemaker.Session.upload_data` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use later when we start the training job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-us-east-1-841336972682/sagemaker/DEMO-pytorch-mnist\n"
     ]
    }
   ],
   "source": [
    "inputs = sagemaker_session.upload_data(path='data', bucket=bucket, key_prefix=prefix)\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "### Training script\n",
    "The `mnist.py` script provides all the code we need for training and hosting a SageMaker model (`model_fn` function to load a model).\n",
    "The training script is very similar to a training script you might run outside of SageMaker, but you can access useful properties about the training environment through various environment variables, such as:\n",
    "\n",
    "* `SM_MODEL_DIR`: A string representing the path to the directory to write model artifacts to.\n",
    "  These artifacts are uploaded to S3 for model hosting.\n",
    "* `SM_NUM_GPUS`: The number of gpus available in the current container.\n",
    "* `SM_CURRENT_HOST`: The name of the current container on the container network.\n",
    "* `SM_HOSTS`: JSON encoded list containing all the hosts .\n",
    "\n",
    "Supposing one input channel, 'training', was used in the call to the `fit()` method, the following will be set, following the format `SM_CHANNEL_[channel_name]`:\n",
    "\n",
    "* `SM_CHANNEL_TRAINING`: A string representing the path to the directory containing data in the 'training' channel.\n",
    "\n",
    "For more information about training environment variables, please visit [SageMaker Containers](https://github.com/aws/sagemaker-containers).\n",
    "\n",
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to `model_dir` so that it can be hosted later. Hyperparameters are passed to your script as arguments and can be retrieved with an `argparse.ArgumentParser` instance.\n",
    "\n",
    "Because the SageMaker imports the training script, you should put your training code in a main guard (``if __name__=='__main__':``) if you are using the same script to host your model as we do in this example, so that SageMaker does not inadvertently run your training code at the wrong point in execution.\n",
    "\n",
    "For example, the script run by this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mdist\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datasets, transforms\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "logger.setLevel(logging.DEBUG)\u001b[37m\u001b[39;49;00m\r\n",
      "logger.addHandler(logging.StreamHandler(sys.stdout))\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m# Based on https://github.com/pytorch/examples/blob/master/mnist/main.py\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mNet\u001b[39;49;00m(nn.Module):\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[36msuper\u001b[39;49;00m(Net, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[36mself\u001b[39;49;00m.conv1 = nn.Conv2d(\u001b[34m1\u001b[39;49;00m, \u001b[34m10\u001b[39;49;00m, kernel_size=\u001b[34m5\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[36mself\u001b[39;49;00m.conv2 = nn.Conv2d(\u001b[34m10\u001b[39;49;00m, \u001b[34m20\u001b[39;49;00m, kernel_size=\u001b[34m5\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[36mself\u001b[39;49;00m.conv2_drop = nn.Dropout2d()\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[36mself\u001b[39;49;00m.fc1 = nn.Linear(\u001b[34m320\u001b[39;49;00m, \u001b[34m50\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[36mself\u001b[39;49;00m.fc2 = nn.Linear(\u001b[34m50\u001b[39;49;00m, \u001b[34m10\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\u001b[37m\u001b[39;49;00m\r\n",
      "        x = F.relu(F.max_pool2d(\u001b[36mself\u001b[39;49;00m.conv1(x), \u001b[34m2\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\r\n",
      "        x = F.relu(F.max_pool2d(\u001b[36mself\u001b[39;49;00m.conv2_drop(\u001b[36mself\u001b[39;49;00m.conv2(x)), \u001b[34m2\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\r\n",
      "        x = x.view(-\u001b[34m1\u001b[39;49;00m, \u001b[34m320\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "        x = F.relu(\u001b[36mself\u001b[39;49;00m.fc1(x))\u001b[37m\u001b[39;49;00m\r\n",
      "        x = F.dropout(x, training=\u001b[36mself\u001b[39;49;00m.training)\u001b[37m\u001b[39;49;00m\r\n",
      "        x = \u001b[36mself\u001b[39;49;00m.fc2(x)\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m F.log_softmax(x, dim=\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_train_data_loader\u001b[39;49;00m(batch_size, training_dir, is_distributed, **kwargs):\u001b[37m\u001b[39;49;00m\r\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mGet train data loader\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    dataset = datasets.MNIST(training_dir, train=\u001b[34mTrue\u001b[39;49;00m, transform=transforms.Compose([\u001b[37m\u001b[39;49;00m\r\n",
      "        transforms.ToTensor(),\u001b[37m\u001b[39;49;00m\r\n",
      "        transforms.Normalize((\u001b[34m0.1307\u001b[39;49;00m,), (\u001b[34m0.3081\u001b[39;49;00m,))\u001b[37m\u001b[39;49;00m\r\n",
      "    ]))\u001b[37m\u001b[39;49;00m\r\n",
      "    train_sampler = torch.utils.data.distributed.DistributedSampler(dataset) \u001b[34mif\u001b[39;49;00m is_distributed \u001b[34melse\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=train_sampler \u001b[35mis\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\r\n",
      "                                       sampler=train_sampler, **kwargs)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_test_data_loader\u001b[39;49;00m(test_batch_size, training_dir, **kwargs):\u001b[37m\u001b[39;49;00m\r\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mGet test data loader\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m torch.utils.data.DataLoader(\u001b[37m\u001b[39;49;00m\r\n",
      "        datasets.MNIST(training_dir, train=\u001b[34mFalse\u001b[39;49;00m, transform=transforms.Compose([\u001b[37m\u001b[39;49;00m\r\n",
      "            transforms.ToTensor(),\u001b[37m\u001b[39;49;00m\r\n",
      "            transforms.Normalize((\u001b[34m0.1307\u001b[39;49;00m,), (\u001b[34m0.3081\u001b[39;49;00m,))\u001b[37m\u001b[39;49;00m\r\n",
      "        ])),\u001b[37m\u001b[39;49;00m\r\n",
      "        batch_size=test_batch_size, shuffle=\u001b[34mTrue\u001b[39;49;00m, **kwargs)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_average_gradients\u001b[39;49;00m(model):\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# Gradient averaging.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    size = \u001b[36mfloat\u001b[39;49;00m(dist.get_world_size())\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mfor\u001b[39;49;00m param \u001b[35min\u001b[39;49;00m model.parameters():\u001b[37m\u001b[39;49;00m\r\n",
      "        dist.all_reduce(param.grad.data, op=dist.reduce_op.SUM, group=\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "        param.grad.data /= size\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(args):\u001b[37m\u001b[39;49;00m\r\n",
      "    is_distributed = \u001b[36mlen\u001b[39;49;00m(args.hosts) > \u001b[34m1\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m args.backend \u001b[35mis\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    logger.debug(\u001b[33m\"\u001b[39;49;00m\u001b[33mDistributed training - \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(is_distributed))\u001b[37m\u001b[39;49;00m\r\n",
      "    use_cuda = args.num_gpus > \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    logger.debug(\u001b[33m\"\u001b[39;49;00m\u001b[33mNumber of gpus available - \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(args.num_gpus))\u001b[37m\u001b[39;49;00m\r\n",
      "    kwargs = {\u001b[33m'\u001b[39;49;00m\u001b[33mnum_workers\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[34m1\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mpin_memory\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[34mTrue\u001b[39;49;00m} \u001b[34mif\u001b[39;49;00m use_cuda \u001b[34melse\u001b[39;49;00m {}\u001b[37m\u001b[39;49;00m\r\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m use_cuda \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mif\u001b[39;49;00m is_distributed:\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[37m# Initialize the distributed environment.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "        world_size = \u001b[36mlen\u001b[39;49;00m(args.hosts)\u001b[37m\u001b[39;49;00m\r\n",
      "        os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mWORLD_SIZE\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[36mstr\u001b[39;49;00m(world_size)\u001b[37m\u001b[39;49;00m\r\n",
      "        host_rank = args.hosts.index(args.current_host)\u001b[37m\u001b[39;49;00m\r\n",
      "        dist.init_process_group(backend=args.backend, rank=host_rank, world_size=world_size)\u001b[37m\u001b[39;49;00m\r\n",
      "        logger.info(\u001b[33m'\u001b[39;49;00m\u001b[33mInitialized the distributed environment: \u001b[39;49;00m\u001b[33m\\'\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\\'\u001b[39;49;00m\u001b[33m backend on \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m nodes. \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\u001b[37m\u001b[39;49;00m\r\n",
      "            args.backend, dist.get_world_size()) + \u001b[33m'\u001b[39;49;00m\u001b[33mCurrent host rank is \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m. Number of gpus: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\u001b[37m\u001b[39;49;00m\r\n",
      "            dist.get_rank(), args.num_gpus))\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# set the seed for generating random numbers\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    torch.manual_seed(args.seed)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mif\u001b[39;49;00m use_cuda:\u001b[37m\u001b[39;49;00m\r\n",
      "        torch.cuda.manual_seed(args.seed)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    train_loader = _get_train_data_loader(args.batch_size, args.data_dir, is_distributed, **kwargs)\u001b[37m\u001b[39;49;00m\r\n",
      "    test_loader = _get_test_data_loader(args.test_batch_size, args.data_dir, **kwargs)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    logger.debug(\u001b[33m\"\u001b[39;49;00m\u001b[33mProcesses \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m) of train data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[36mlen\u001b[39;49;00m(train_loader.sampler), \u001b[36mlen\u001b[39;49;00m(train_loader.dataset),\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[34m100.\u001b[39;49;00m * \u001b[36mlen\u001b[39;49;00m(train_loader.sampler) / \u001b[36mlen\u001b[39;49;00m(train_loader.dataset)\u001b[37m\u001b[39;49;00m\r\n",
      "    ))\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    logger.debug(\u001b[33m\"\u001b[39;49;00m\u001b[33mProcesses \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m) of test data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[36mlen\u001b[39;49;00m(test_loader.sampler), \u001b[36mlen\u001b[39;49;00m(test_loader.dataset),\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[34m100.\u001b[39;49;00m * \u001b[36mlen\u001b[39;49;00m(test_loader.sampler) / \u001b[36mlen\u001b[39;49;00m(test_loader.dataset)\u001b[37m\u001b[39;49;00m\r\n",
      "    ))\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    model = Net().to(device)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mif\u001b[39;49;00m is_distributed \u001b[35mand\u001b[39;49;00m use_cuda:\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[37m# multi-machine multi-gpu case\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "        model = torch.nn.parallel.DistributedDataParallel(model)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[37m# single-machine multi-gpu case or single-machine or multi-machine cpu case\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "        model = torch.nn.DataParallel(model)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m1\u001b[39;49;00m, args.epochs + \u001b[34m1\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\r\n",
      "        model.train()\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[34mfor\u001b[39;49;00m batch_idx, (data, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(train_loader, \u001b[34m1\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\r\n",
      "            data, target = data.to(device), target.to(device)\u001b[37m\u001b[39;49;00m\r\n",
      "            optimizer.zero_grad()\u001b[37m\u001b[39;49;00m\r\n",
      "            output = model(data)\u001b[37m\u001b[39;49;00m\r\n",
      "            loss = F.nll_loss(output, target)\u001b[37m\u001b[39;49;00m\r\n",
      "            loss.backward()\u001b[37m\u001b[39;49;00m\r\n",
      "            \u001b[34mif\u001b[39;49;00m is_distributed \u001b[35mand\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m use_cuda:\u001b[37m\u001b[39;49;00m\r\n",
      "                \u001b[37m# average gradients manually for multi-machine cpu case only\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "                _average_gradients(model)\u001b[37m\u001b[39;49;00m\r\n",
      "            optimizer.step()\u001b[37m\u001b[39;49;00m\r\n",
      "            \u001b[34mif\u001b[39;49;00m batch_idx % args.log_interval == \u001b[34m0\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\r\n",
      "                logger.info(\u001b[33m'\u001b[39;49;00m\u001b[33mTrain Epoch: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m [\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m)] Loss: \u001b[39;49;00m\u001b[33m{:.6f}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\u001b[37m\u001b[39;49;00m\r\n",
      "                    epoch, batch_idx * \u001b[36mlen\u001b[39;49;00m(data), \u001b[36mlen\u001b[39;49;00m(train_loader.sampler),\u001b[37m\u001b[39;49;00m\r\n",
      "                    \u001b[34m100.\u001b[39;49;00m * batch_idx / \u001b[36mlen\u001b[39;49;00m(train_loader), loss.item()))\u001b[37m\u001b[39;49;00m\r\n",
      "        test(model, test_loader, device)\u001b[37m\u001b[39;49;00m\r\n",
      "    save_model(model, args.model_dir)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtest\u001b[39;49;00m(model, test_loader, device):\u001b[37m\u001b[39;49;00m\r\n",
      "    model.eval()\u001b[37m\u001b[39;49;00m\r\n",
      "    test_loss = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    correct = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[34mfor\u001b[39;49;00m data, target \u001b[35min\u001b[39;49;00m test_loader:\u001b[37m\u001b[39;49;00m\r\n",
      "            data, target = data.to(device), target.to(device)\u001b[37m\u001b[39;49;00m\r\n",
      "            output = model(data)\u001b[37m\u001b[39;49;00m\r\n",
      "            test_loss += F.nll_loss(output, target, size_average=\u001b[34mFalse\u001b[39;49;00m).item()  \u001b[37m# sum up batch loss\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "            pred = output.max(\u001b[34m1\u001b[39;49;00m, keepdim=\u001b[34mTrue\u001b[39;49;00m)[\u001b[34m1\u001b[39;49;00m]  \u001b[37m# get the index of the max log-probability\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "            correct += pred.eq(target.view_as(pred)).sum().item()\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    test_loss /= \u001b[36mlen\u001b[39;49;00m(test_loader.dataset)\u001b[37m\u001b[39;49;00m\r\n",
      "    logger.info(\u001b[33m'\u001b[39;49;00m\u001b[33mTest set: Average loss: \u001b[39;49;00m\u001b[33m{:.4f}\u001b[39;49;00m\u001b[33m, Accuracy: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m)\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\u001b[37m\u001b[39;49;00m\r\n",
      "        test_loss, correct, \u001b[36mlen\u001b[39;49;00m(test_loader.dataset),\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[34m100.\u001b[39;49;00m * correct / \u001b[36mlen\u001b[39;49;00m(test_loader.dataset)))\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\u001b[37m\u001b[39;49;00m\r\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    model = torch.nn.DataParallel(Net())\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\u001b[37m\u001b[39;49;00m\r\n",
      "        model.load_state_dict(torch.load(f))\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m model.to(device)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_model\u001b[39;49;00m(model, model_dir):\u001b[37m\u001b[39;49;00m\r\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving the model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# recommended way from http://pytorch.org/docs/master/notes/serialization.html\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    torch.save(model.cpu().state_dict(), path)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\r\n",
      "    parser = argparse.ArgumentParser()\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# Data and model checkpoints directories\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minput batch size for training (default: 64)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--test-batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1000\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minput batch size for testing (default: 1000)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of epochs to train (default: 10)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.01\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mLR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mlearning rate (default: 0.01)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--momentum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.5\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mSGD momentum (default: 0.5)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--seed\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mrandom seed (default: 1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--log-interval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m100\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mhow many batches to wait before logging training status\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--backend\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[34mNone\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mbackend for distributed training (tcp, gloo on cpu and gloo, nccl on gpu)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# Container environment\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\u001b[37m\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--num-gpus\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[37m\u001b[39;49;00m\r\n",
      "    train(parser.parse_args())\u001b[37m\u001b[39;49;00m\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize mnist.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up hyperparameter tuning job\n",
    "*Note, with the default setting below, the hyperparameter tuning job can take about 20 minutes to complete.*\n",
    "\n",
    "Now that we have prepared the dataset and the script, we are ready to train models. Before we do that, one thing to note is there are many hyperparameters that can dramtically affect the performance of the trained models. For example, learning rate, batch size, number of epochs, etc. Since which hyperparameter setting can lead to the best result depends on the dataset as well, it is almost impossible to pick the best hyperparameter setting without searching for it. Using SageMaker Automatic Model Tuning, we can create a hyperparameter tuning job to search for the best hyperparameter setting in an automated and effective way.\n",
    "\n",
    "In this example, we are using SageMaker Python SDK to set up and manage a hyperparameter tuning job. Specifically, we specify a range, or a list of possible values in the case of categorical hyperparameters, for each of the hyperparameter that we plan to tune. The hyperparameter tuning job will automatically launch multiple training jobs with different hyperparameter settings, evaluate results of those training jobs based on a predefined \"objective metric\", and select the hyperparameter settings for future attempts based on previous results. For each hyperparameter tuning job, we will give it a budget (max number of training jobs) and it will complete once that many training jobs have been executed.\n",
    "\n",
    "Now we will set up the hyperparameter tuning job using SageMaker Python SDK, following below steps:\n",
    "* Create an estimator to set up the PyTorch training job\n",
    "* Define the ranges of hyperparameters we plan to tune, in this example, we are tuning learning_rate and batch size\n",
    "* Define the objective metric for the tuning job to optimize\n",
    "* Create a hyperparameter tuner with above setting, as well as tuning resource configurations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to training a single PyTorch job in SageMaker, we define our PyTorch estimator passing in the PyTorch script, IAM role, and (per job) hardware configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point=\"mnist.py\",\n",
    "                    role=role,\n",
    "                    framework_version='1.13.1',\n",
    "                    py_version='py39',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.m4.xlarge',\n",
    "                    hyperparameters={\n",
    "                        'epochs': 6,\n",
    "                        'backend': 'gloo'\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've defined our estimator we can specify the hyperparameters we'd like to tune and their possible values.  We have three different types of hyperparameters.\n",
    "- Categorical parameters need to take one value from a discrete set.  We define this by passing the list of possible values to `CategoricalParameter(list)`\n",
    "- Continuous parameters can take any real number value between the minimum and maximum value, defined by `ContinuousParameter(min, max)`\n",
    "- Integer parameters can take any integer value between the minimum and maximum value, defined by `IntegerParameter(min, max)`\n",
    "\n",
    "*Note, if possible, it's almost always best to specify a value as the least restrictive type.  For example, tuning learning rate as a continuous value between 0.01 and 0.2 is likely to yield a better result than tuning as a categorical parameter with values 0.01, 0.1, 0.15, or 0.2. We did specify batch size as categorical parameter here since it is generally recommended to be the power of 2.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {'lr': ContinuousParameter(0.001, 0.1),'batch-size': CategoricalParameter([32,64,128,256,512])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll specify the objective metric that we'd like to tune and its definition, which includes the regular expression (Regex) needed to extract that metric from the CloudWatch logs of the training job. In this particular case, our script emits average loss value and we will use it as the objective metric, we also set the objective_type to be 'minimize', so that hyperparameter tuning seeks to minize the objective metric when searching for the best hyperparameter setting. By default, objective_type is set to 'maximize'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "objective_metric_name = 'average test loss'\n",
    "objective_type = 'Minimize'\n",
    "metric_definitions = [{'Name': 'average test loss',\n",
    "                       'Regex': 'Test set: Average loss: ([0-9\\\\.]+)'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a `HyperparameterTuner` object, to which we pass:\n",
    "- The PyTorch estimator we created above\n",
    "- Our hyperparameter ranges\n",
    "- Objective metric name and definition\n",
    "- Tuning resource configurations such as Number of training jobs to run in total and how many training jobs can be run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            max_jobs=6,\n",
    "                            max_parallel_jobs=3,\n",
    "                            objective_type=objective_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch hyperparameter tuning job\n",
    "And finally, we can start our hyperprameter tuning job by calling `.fit()` and passing in the S3 path to our train and test dataset.\n",
    "\n",
    "After the hyperprameter tuning job is created, you should be able to describe the tuning job to see its progress in the next step, and you can go to SageMaker console->Jobs to check out the progress of the progress of the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................................................................................................................................!\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit({'training': inputs})\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Host\n",
    "### Create endpoint\n",
    "After training, we use the tuner object to build and deploy a `PyTorchPredictor`. This creates a Sagemaker Endpoint -- a hosted prediction service that we can use to perform inference, based on the best model in the tuner. Remember in previous steps, the tuner launched multiple training jobs during tuning and the resulting model with the best objective metric is defined as the best model. \n",
    "\n",
    "As mentioned above we have implementation of `model_fn` in the `mnist.py` script that is required. We are going to use default implementations of `input_fn`, `predict_fn`, `output_fn` and `transform_fm` defined in [sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-containers).\n",
    "\n",
    "The arguments to the deploy function allow us to set the number and type of instances that will be used for the Endpoint. These do not need to be the same as the values we used for the training job. For example, you can train a model on a set of GPU-based instances, and then deploy the Endpoint to a fleet of CPU-based instances, but you need to make sure that you return or save your model as a cpu model similar to what we did in `mnist.py`. Here we will deploy the model to a single ```ml.m4.xlarge``` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-03-23 10:23:04 Starting - Found matching resource for reuse\n",
      "2023-03-23 10:23:04 Downloading - Downloading input data\n",
      "2023-03-23 10:23:04 Training - Training image download completed. Training in progress.\n",
      "2023-03-23 10:23:04 Uploading - Uploading generated training model\n",
      "2023-03-23 10:23:04 Completed - Resource retained for reuse\n",
      "-------!"
     ]
    }
   ],
   "source": [
    "predictor = tuner.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "We can now use this predictor to classify hand-written digits. \n",
    "\n",
    "We'll download the test data from the built-in dataset from torchvision and use a couple of images for testing the model.\n",
    "\n",
    "Note that we apply the same transformations to the dataset and convert the tensor to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = datasets.MNIST(root='data', train=False, download=True, transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset))\n",
    "test_dataset_array = next(iter(test_loader))[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose an image for passing to the predictor and obtaining a prediction. Change the value of `idx` to pick a different image for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "test_image = test_dataset_array[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(test_image.reshape(28, 28), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the chosen image to the predictor to obtain the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "response = predictor.predict(test_image)\n",
    "prediction = response.argmax(axis=1)[0]\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "After you have finished with this example, remember to delete the prediction endpoint to release the instance(s) associated with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
